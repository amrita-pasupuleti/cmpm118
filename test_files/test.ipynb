{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 61.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 191kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.64MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 22.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "# Split the training set for validation\n",
    "train_size = 50000\n",
    "val_size = 10000\n",
    "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        running_accuracy += correct / len(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 500 == 499:\n",
    "            avg_loss_across_batches = running_loss / 500\n",
    "            avg_acc_across_batches = (running_accuracy / 500) * 100\n",
    "            print(f'Batch {batch_index+1}, Loss: {avg_loss_across_batches:.3f}, Accuracy: {avg_acc_across_batches:.1f}%')\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            running_accuracy += correct / len(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(val_loader)\n",
    "    avg_acc_across_batches = (running_accuracy / len(val_loader)) * 100\n",
    "\n",
    "    print(f'Val Loss: {avg_loss_across_batches:.3f}, Val Accuracy: {avg_acc_across_batches:.1f}%')\n",
    "    print('***************************************************')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\n",
      "Batch 500, Loss: 1.425, Accuracy: 51.1%\n",
      "Batch 1000, Loss: 1.072, Accuracy: 62.7%\n",
      "Batch 1500, Loss: 0.872, Accuracy: 70.3%\n",
      "Batch 2000, Loss: 0.777, Accuracy: 72.9%\n",
      "Batch 2500, Loss: 0.722, Accuracy: 75.1%\n",
      "Batch 3000, Loss: 0.671, Accuracy: 77.0%\n",
      "Batch 3500, Loss: 0.638, Accuracy: 77.5%\n",
      "Batch 4000, Loss: 0.585, Accuracy: 80.4%\n",
      "Batch 4500, Loss: 0.590, Accuracy: 79.8%\n",
      "Batch 5000, Loss: 0.549, Accuracy: 81.1%\n",
      "Batch 5500, Loss: 0.518, Accuracy: 82.4%\n",
      "Batch 6000, Loss: 0.531, Accuracy: 82.5%\n",
      "\n",
      "Val Loss: 0.412, Val Accuracy: 85.1%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Batch 500, Loss: 0.467, Accuracy: 84.4%\n",
      "Batch 1000, Loss: 0.469, Accuracy: 83.0%\n",
      "Batch 1500, Loss: 0.507, Accuracy: 83.7%\n",
      "Batch 2000, Loss: 0.462, Accuracy: 84.1%\n",
      "Batch 2500, Loss: 0.462, Accuracy: 84.0%\n",
      "Batch 3000, Loss: 0.443, Accuracy: 85.0%\n",
      "Batch 3500, Loss: 0.414, Accuracy: 85.5%\n",
      "Batch 4000, Loss: 0.410, Accuracy: 86.0%\n",
      "Batch 4500, Loss: 0.404, Accuracy: 86.2%\n",
      "Batch 5000, Loss: 0.412, Accuracy: 85.4%\n",
      "Batch 5500, Loss: 0.435, Accuracy: 85.2%\n",
      "Batch 6000, Loss: 0.387, Accuracy: 87.0%\n",
      "\n",
      "Val Loss: 0.348, Val Accuracy: 87.8%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Batch 500, Loss: 0.365, Accuracy: 87.2%\n",
      "Batch 1000, Loss: 0.384, Accuracy: 86.7%\n",
      "Batch 1500, Loss: 0.350, Accuracy: 87.7%\n",
      "Batch 2000, Loss: 0.365, Accuracy: 86.9%\n",
      "Batch 2500, Loss: 0.334, Accuracy: 88.2%\n",
      "Batch 3000, Loss: 0.384, Accuracy: 86.8%\n",
      "Batch 3500, Loss: 0.341, Accuracy: 87.6%\n",
      "Batch 4000, Loss: 0.376, Accuracy: 86.9%\n",
      "Batch 4500, Loss: 0.339, Accuracy: 88.3%\n",
      "Batch 5000, Loss: 0.335, Accuracy: 88.7%\n",
      "Batch 5500, Loss: 0.341, Accuracy: 88.5%\n",
      "Batch 6000, Loss: 0.333, Accuracy: 87.8%\n",
      "\n",
      "Val Loss: 0.308, Val Accuracy: 89.2%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Batch 500, Loss: 0.286, Accuracy: 90.4%\n",
      "Batch 1000, Loss: 0.318, Accuracy: 88.5%\n",
      "Batch 1500, Loss: 0.299, Accuracy: 90.1%\n",
      "Batch 2000, Loss: 0.309, Accuracy: 88.9%\n",
      "Batch 2500, Loss: 0.297, Accuracy: 89.5%\n",
      "Batch 3000, Loss: 0.311, Accuracy: 88.7%\n",
      "Batch 3500, Loss: 0.317, Accuracy: 88.6%\n",
      "Batch 4000, Loss: 0.304, Accuracy: 89.1%\n",
      "Batch 4500, Loss: 0.284, Accuracy: 90.0%\n",
      "Batch 5000, Loss: 0.321, Accuracy: 88.8%\n",
      "Batch 5500, Loss: 0.285, Accuracy: 89.8%\n",
      "Batch 6000, Loss: 0.319, Accuracy: 88.7%\n",
      "\n",
      "Val Loss: 0.295, Val Accuracy: 89.2%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "Batch 500, Loss: 0.275, Accuracy: 89.9%\n",
      "Batch 1000, Loss: 0.274, Accuracy: 90.1%\n",
      "Batch 1500, Loss: 0.280, Accuracy: 90.1%\n",
      "Batch 2000, Loss: 0.285, Accuracy: 89.6%\n",
      "Batch 2500, Loss: 0.274, Accuracy: 90.2%\n",
      "Batch 3000, Loss: 0.271, Accuracy: 90.2%\n",
      "Batch 3500, Loss: 0.252, Accuracy: 91.4%\n",
      "Batch 4000, Loss: 0.275, Accuracy: 90.3%\n",
      "Batch 4500, Loss: 0.288, Accuracy: 89.1%\n",
      "Batch 5000, Loss: 0.271, Accuracy: 90.2%\n",
      "Batch 5500, Loss: 0.258, Accuracy: 90.9%\n",
      "Batch 6000, Loss: 0.259, Accuracy: 90.8%\n",
      "\n",
      "Val Loss: 0.270, Val Accuracy: 90.0%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "Batch 500, Loss: 0.248, Accuracy: 91.1%\n",
      "Batch 1000, Loss: 0.229, Accuracy: 91.1%\n",
      "Batch 1500, Loss: 0.265, Accuracy: 90.4%\n",
      "Batch 2000, Loss: 0.256, Accuracy: 91.2%\n",
      "Batch 2500, Loss: 0.262, Accuracy: 90.7%\n",
      "Batch 3000, Loss: 0.253, Accuracy: 90.7%\n",
      "Batch 3500, Loss: 0.244, Accuracy: 91.2%\n",
      "Batch 4000, Loss: 0.240, Accuracy: 91.5%\n",
      "Batch 4500, Loss: 0.246, Accuracy: 91.1%\n",
      "Batch 5000, Loss: 0.238, Accuracy: 91.4%\n",
      "Batch 5500, Loss: 0.246, Accuracy: 91.5%\n",
      "Batch 6000, Loss: 0.227, Accuracy: 91.5%\n",
      "\n",
      "Val Loss: 0.263, Val Accuracy: 90.6%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "Batch 500, Loss: 0.214, Accuracy: 91.8%\n",
      "Batch 1000, Loss: 0.213, Accuracy: 92.5%\n",
      "Batch 1500, Loss: 0.217, Accuracy: 92.1%\n",
      "Batch 2000, Loss: 0.216, Accuracy: 92.0%\n",
      "Batch 2500, Loss: 0.226, Accuracy: 92.0%\n",
      "Batch 3000, Loss: 0.250, Accuracy: 91.5%\n",
      "Batch 3500, Loss: 0.239, Accuracy: 91.7%\n",
      "Batch 4000, Loss: 0.229, Accuracy: 91.6%\n",
      "Batch 4500, Loss: 0.224, Accuracy: 91.8%\n",
      "Batch 5000, Loss: 0.221, Accuracy: 92.3%\n",
      "Batch 5500, Loss: 0.224, Accuracy: 91.5%\n",
      "Batch 6000, Loss: 0.230, Accuracy: 91.6%\n",
      "\n",
      "Val Loss: 0.254, Val Accuracy: 90.8%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "Batch 500, Loss: 0.196, Accuracy: 92.7%\n",
      "Batch 1000, Loss: 0.210, Accuracy: 92.5%\n",
      "Batch 1500, Loss: 0.209, Accuracy: 92.2%\n",
      "Batch 2000, Loss: 0.206, Accuracy: 92.4%\n",
      "Batch 2500, Loss: 0.210, Accuracy: 92.1%\n",
      "Batch 3000, Loss: 0.195, Accuracy: 93.1%\n",
      "Batch 3500, Loss: 0.220, Accuracy: 92.2%\n",
      "Batch 4000, Loss: 0.208, Accuracy: 92.2%\n",
      "Batch 4500, Loss: 0.205, Accuracy: 93.0%\n",
      "Batch 5000, Loss: 0.223, Accuracy: 92.1%\n",
      "Batch 5500, Loss: 0.212, Accuracy: 92.6%\n",
      "Batch 6000, Loss: 0.199, Accuracy: 92.9%\n",
      "\n",
      "Val Loss: 0.267, Val Accuracy: 90.5%\n",
      "***************************************************\n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "Batch 500, Loss: 0.165, Accuracy: 94.1%\n",
      "Batch 1000, Loss: 0.179, Accuracy: 93.6%\n",
      "Batch 1500, Loss: 0.179, Accuracy: 93.3%\n",
      "Batch 2000, Loss: 0.186, Accuracy: 93.2%\n",
      "Batch 2500, Loss: 0.191, Accuracy: 93.3%\n",
      "Batch 3000, Loss: 0.182, Accuracy: 93.0%\n",
      "Batch 3500, Loss: 0.184, Accuracy: 93.4%\n",
      "Batch 4000, Loss: 0.202, Accuracy: 92.8%\n",
      "Batch 4500, Loss: 0.207, Accuracy: 92.4%\n",
      "Batch 5000, Loss: 0.180, Accuracy: 93.2%\n",
      "Batch 5500, Loss: 0.180, Accuracy: 93.9%\n",
      "Batch 6000, Loss: 0.212, Accuracy: 92.1%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch_index in range(num_epochs):\n",
    "    print(f'Epoch: {epoch_index + 1}\\n')\n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
